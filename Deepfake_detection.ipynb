{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2220df6",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7249bea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (3.39.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: aiohttp~=3.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (3.9.5)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (5.3.0)\n",
      "Requirement already satisfied: fastapi in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (0.111.0)\n",
      "Requirement already satisfied: ffmpy in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (0.3.2)\n",
      "Requirement already satisfied: gradio-client>=0.3.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (0.16.4)\n",
      "Requirement already satisfied: httpx in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (0.23.0)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.0.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.2.0)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (3.9.0)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (0.3.3)\n",
      "Requirement already satisfied: numpy~=1.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (3.10.3)\n",
      "Requirement already satisfied: packaging in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (24.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (2.7.1)\n",
      "Requirement already satisfied: pydub in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: requests~=2.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (2.31.0)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (4.11.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (0.29.0)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio) (11.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from aiohttp~=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from aiohttp~=3.0->gradio) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from aiohttp~=3.0->gradio) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from aiohttp~=3.0->gradio) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from aiohttp~=3.0->gradio) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from aiohttp~=3.0->gradio) (4.0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.22.0)\n",
      "Requirement already satisfied: toolz in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fsspec in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from gradio-client>=0.3.0->gradio) (2024.5.0)\n",
      "Requirement already satisfied: anyio in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from httpx->gradio) (4.3.0)\n",
      "Requirement already satisfied: certifi in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from httpx->gradio) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from httpx->gradio) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from httpx->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from httpx->gradio) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from httpcore==1.*->httpx->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (3.14.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (4.66.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from matplotlib~=3.0->gradio) (6.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio) (2.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from requests~=2.0->gradio) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from requests~=2.0->gradio) (2.2.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (8.1.7)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from fastapi->gradio) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from fastapi->gradio) (0.0.3)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from fastapi->gradio) (5.10.0)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from fastapi->gradio) (2.1.1)\n",
      "Requirement already satisfied: colorama in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from click>=7.0->uvicorn>=0.14.0->gradio) (0.4.6)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from email_validator>=2.0.0->fastapi->gradio) (2.6.1)\n",
      "Requirement already satisfied: typer>=0.12.3 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from fastapi-cli>=0.0.2->fastapi->gradio) (0.12.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib~=3.0->gradio) (3.18.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
      "Requirement already satisfied: uc-micro-py in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from anyio->httpx->gradio) (1.2.1)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio) (0.21.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->gradio) (13.7.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\kandikits\\deepfake-detection\\deepfake-detection-env\\lib\\site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->gradio) (2.18.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio\n",
    "import gradio as gr\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25e1c5d",
   "metadata": {},
   "source": [
    "# Download and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "237fbf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "mtcnn = MTCNN(\n",
    "    select_largest=False,\n",
    "    post_process=False,\n",
    "    device=DEVICE\n",
    ").to(DEVICE).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3ef2b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InceptionResnetV1(\n",
       "  (conv2d_1a): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv2d_2a): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv2d_2b): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2d_3b): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv2d_4a): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv2d_4b): BasicConv2d(\n",
       "    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (repeat_1): Sequential(\n",
       "    (0): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): Block35(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mixed_6a): Mixed_6a(\n",
       "    (branch0): BasicConv2d(\n",
       "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (branch1): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (repeat_2): Sequential(\n",
       "    (0): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (6): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (7): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (8): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (9): Block17(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mixed_7a): Mixed_7a(\n",
       "    (branch0): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch1): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): BasicConv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (repeat_3): Sequential(\n",
       "    (0): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (block8): Block8(\n",
       "    (branch0): BasicConv2d(\n",
       "      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (branch1): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): BasicConv2d(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n",
       "  (dropout): Dropout(p=0.6, inplace=False)\n",
       "  (last_linear): Linear(in_features=1792, out_features=512, bias=False)\n",
       "  (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (logits): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = InceptionResnetV1(\n",
    "    pretrained=\"vggface2\",\n",
    "    classify=True,\n",
    "    num_classes=1,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "checkpoint = torch.load(\"resnetinceptionv1_epoch_32.pth\", map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a499194a",
   "metadata": {},
   "source": [
    "# Model Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "376e6cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_image:Image.Image):\n",
    "    \"\"\"Predict the label of the input_image\"\"\"\n",
    "    face = mtcnn(input_image)\n",
    "    if face is None:\n",
    "        print('Provided Image is not contain a face')\n",
    "    face = face.unsqueeze(0) # add the batch dimension\n",
    "    face = F.interpolate(face, size=(256, 256), mode='bilinear', align_corners=False)\n",
    "    \n",
    "    # convert the face into a numpy array to be able to plot it\n",
    "    prev_face = face.squeeze(0).permute(1, 2, 0).cpu().detach().int().numpy()\n",
    "    prev_face = prev_face.astype('uint8')\n",
    "\n",
    "    face = face.to(DEVICE)\n",
    "    face = face.to(torch.float32)\n",
    "    face = face / 255.0\n",
    "    face_image_to_plot = face.squeeze(0).permute(1, 2, 0).cpu().detach().int().numpy()\n",
    "\n",
    "    target_layers=[model.block8.branch1[-1]]\n",
    "    use_cuda = True if torch.cuda.is_available() else False\n",
    "    cam = GradCAM(model=model, target_layers=target_layers, use_cuda=use_cuda)\n",
    "    targets = [ClassifierOutputTarget(0)]\n",
    "\n",
    "    grayscale_cam = cam(input_tensor=face, targets=targets, eigen_smooth=True)\n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "    visualization = show_cam_on_image(face_image_to_plot, grayscale_cam, use_rgb=True)\n",
    "    face_with_mask = cv2.addWeighted(prev_face, 1, visualization, 0.5, 0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = torch.sigmoid(model(face).squeeze(0))\n",
    "        prediction = \"real\" if output.item() < 0.5 else \"fake\"\n",
    "        \n",
    "        real_prediction = 1 - output.item()\n",
    "        fake_prediction = output.item()\n",
    "        \n",
    "        confidences = {\n",
    "            'real': real_prediction,\n",
    "            'fake': fake_prediction\n",
    "        }\n",
    "    return confidences, face_with_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f47b5a",
   "metadata": {},
   "source": [
    "# Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d62177b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.39.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "interface = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=[\n",
    "        gr.inputs.Image(label=\"Input Image\", type=\"pil\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.outputs.Label(label=\"Class\"),\n",
    "        gr.outputs.Image(label=\"Face with Explainability\", type=\"pil\")\n",
    "    ],\n",
    ").launch()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4860fbec-ae3e-40a1-b1e7-dc870d8a60bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.39.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# changing path to new folder( raw) :\n",
    "FLAGGED_FILES_DIRECTORY = \"C:/Users/samar/Pictures/raw\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(FLAGGED_FILES_DIRECTORY, exist_ok=True)\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "mtcnn = MTCNN(\n",
    "    select_largest=False,\n",
    "    post_process=False,\n",
    "    device=DEVICE\n",
    ").to(DEVICE).eval()\n",
    "model = InceptionResnetV1(\n",
    "    pretrained=\"vggface2\",\n",
    "    classify=True,\n",
    "    num_classes=1,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "checkpoint = torch.load(\"resnetinceptionv1_epoch_32.pth\", map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def predict(input_image: Image.Image):\n",
    "    \"\"\"Predict the label of the input_image\"\"\"\n",
    "    face = mtcnn(input_image)\n",
    "    if face is None:\n",
    "        raise Exception('No face detected')\n",
    "    face = face.unsqueeze(0)  # add the batch dimension\n",
    "    face = F.interpolate(face, size=(256, 256), mode='bilinear', align_corners=False)\n",
    "\n",
    "    # convert the face into a numpy array to be able to plot it\n",
    "    prev_face = face.squeeze(0).permute(1, 2, 0).cpu().detach().int().numpy()\n",
    "    prev_face = prev_face.astype('uint8')\n",
    "\n",
    "    face = face.to(DEVICE)\n",
    "    face = face.to(torch.float32)\n",
    "    face = face / 255.0\n",
    "    face_image_to_plot = face.squeeze(0).permute(1, 2, 0).cpu().detach().int().numpy()\n",
    "\n",
    "    target_layers = [model.block8.branch1[-1]]\n",
    "    use_cuda = True if torch.cuda.is_available() else False\n",
    "    cam = GradCAM(model=model, target_layers=target_layers, use_cuda=use_cuda)\n",
    "    targets = [ClassifierOutputTarget(0)]\n",
    "\n",
    "    grayscale_cam = cam(input_tensor=face, targets=targets, eigen_smooth=True)\n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "    visualization = show_cam_on_image(face_image_to_plot, grayscale_cam, use_rgb=True)\n",
    "    face_with_mask = cv2.addWeighted(prev_face, 1, visualization, 0.5, 0)\n",
    "\n",
    "    # Save the flagged image\n",
    "    flagged_image_path = os.path.join(FLAGGED_FILES_DIRECTORY, \"flagged_image.png\")\n",
    "    cv2.imwrite(flagged_image_path, face_with_mask)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = torch.sigmoid(model(face).squeeze(0))\n",
    "        prediction = \"real\" if output.item() < 0.5 else \"fake\"\n",
    "\n",
    "        real_prediction = 1 - output.item()\n",
    "        fake_prediction = output.item()\n",
    "\n",
    "        confidences = {\n",
    "            'real': real_prediction,\n",
    "            'fake': fake_prediction\n",
    "        }\n",
    "    return confidences, flagged_image_path\n",
    "\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=[gr.inputs.Image(label=\"Input Image\", type=\"pil\")],\n",
    "    outputs=[gr.outputs.Label(label=\"Class\"), gr.outputs.Image(label=\"Face with Explainability\", type=\"pil\")],\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde9711-9dff-4c56-b234-0055c9903e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5962dc6a-eb9a-4cb0-adfa-e6d24ab1a50c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a59331dd-9438-4720-9366-6542a708e516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.39.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set the directories for flagged images of real and fake images\n",
    "FLAGGED_FILES_REAL_DIRECTORY = \"C:/Users/samar/Pictures/raw/real_images\"\n",
    "FLAGGED_FILES_FAKE_DIRECTORY = \"C:/Users/samar/Pictures/raw/fake_images\"\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(FLAGGED_FILES_REAL_DIRECTORY, exist_ok=True)\n",
    "os.makedirs(FLAGGED_FILES_FAKE_DIRECTORY, exist_ok=True)\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "mtcnn = MTCNN(\n",
    "    select_largest=False,\n",
    "    post_process=False,\n",
    "    device=DEVICE\n",
    ").to(DEVICE).eval()\n",
    "model = InceptionResnetV1(\n",
    "    pretrained=\"vggface2\",\n",
    "    classify=True,\n",
    "    num_classes=1,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "checkpoint = torch.load(\"resnetinceptionv1_epoch_32.pth\", map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def predict(input_image: Image.Image):\n",
    "    \"\"\"Predict the label of the input_image\"\"\"\n",
    "    face = mtcnn(input_image)\n",
    "    if face is None:\n",
    "        raise Exception('No face detected')\n",
    "    face = face.unsqueeze(0)  # add the batch dimension\n",
    "    face = F.interpolate(face, size=(256, 256), mode='bilinear', align_corners=False)\n",
    "\n",
    "    # convert the face into a numpy array to be able to plot it\n",
    "    prev_face = face.squeeze(0).permute(1, 2, 0).cpu().detach().int().numpy()\n",
    "    prev_face = prev_face.astype('uint8')\n",
    "\n",
    "    face = face.to(DEVICE)\n",
    "    face = face.to(torch.float32)\n",
    "    face = face / 255.0\n",
    "    face_image_to_plot = face.squeeze(0).permute(1, 2, 0).cpu().detach().int().numpy()\n",
    "\n",
    "    target_layers = [model.block8.branch1[-1]]\n",
    "    use_cuda = True if torch.cuda.is_available() else False\n",
    "    cam = GradCAM(model=model, target_layers=target_layers, use_cuda=use_cuda)\n",
    "    targets = [ClassifierOutputTarget(0)]\n",
    "\n",
    "    grayscale_cam = cam(input_tensor=face, targets=targets, eigen_smooth=True)\n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "    visualization = show_cam_on_image(face_image_to_plot, grayscale_cam, use_rgb=True)\n",
    "    face_with_mask = cv2.addWeighted(prev_face, 1, visualization, 0.5, 0)\n",
    "\n",
    "    # Save the flagged image based on the prediction\n",
    "    with torch.no_grad():\n",
    "        output = torch.sigmoid(model(face).squeeze(0))\n",
    "        prediction = \"real\" if output.item() < 0.5 else \"fake\" ####\n",
    "        if prediction == \"real\":\n",
    "            flagged_image_path = os.path.join(FLAGGED_FILES_REAL_DIRECTORY, \"flagged_image.png\")\n",
    "        else:\n",
    "            flagged_image_path = os.path.join(FLAGGED_FILES_FAKE_DIRECTORY, \"flagged_image.png\")\n",
    "\n",
    "        cv2.imwrite(flagged_image_path, face_with_mask)\n",
    "\n",
    "        real_prediction = 1 - output.item()\n",
    "        fake_prediction = output.item()\n",
    "\n",
    "        confidences = {\n",
    "            'real': real_prediction,\n",
    "            'fake': fake_prediction\n",
    "        }\n",
    "    return confidences, flagged_image_path\n",
    "\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=[gr.inputs.Image(label=\"Input Image\", type=\"pil\")],\n",
    "    outputs=[gr.outputs.Label(label=\"Class\"), gr.outputs.Image(label=\"Face with Explainability\", type=\"pil\")],\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d58b150-dbd5-4069-989b-78d3ce898207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758bac5a-ce89-4cc0-8d5f-95ed690ef0e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597c6408-9eef-4350-b84f-4bdf30f27c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2d82aa5-4baa-412d-aaa9-c8927ba85ce2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.dnn' has no attribute 'DictValue'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_grad_cam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradCAM\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_grad_cam\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_targets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClassifierOutputTarget\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\cv2\\__init__.py:190\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra Python code for\u001b[39m\u001b[38;5;124m\"\u001b[39m, submodule, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis loaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpenCV loader: DONE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 190\u001b[0m \u001b[43mbootstrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\cv2\\__init__.py:184\u001b[0m, in \u001b[0;36mbootstrap\u001b[1;34m()\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpenCV loader: binary extension... OK\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m submodule \u001b[38;5;129;01min\u001b[39;00m __collect_extra_submodules(DEBUG):\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m__load_extra_py_code_for_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcv2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEBUG\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    185\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra Python code for\u001b[39m\u001b[38;5;124m\"\u001b[39m, submodule, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis loaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpenCV loader: DONE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\cv2\\__init__.py:37\u001b[0m, in \u001b[0;36m__load_extra_py_code_for_module\u001b[1;34m(base, name, enable_debug_print)\u001b[0m\n\u001b[0;32m     35\u001b[0m native_module \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mpop(module_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 37\u001b[0m     py_module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m enable_debug_print:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\cv2\\typing\\__init__.py:169\u001b[0m\n\u001b[0;32m    167\u001b[0m ExtractArgsCallback \u001b[38;5;241m=\u001b[39m typing\u001b[38;5;241m.\u001b[39mCallable[[typing\u001b[38;5;241m.\u001b[39mSequence[GTypeInfo]], typing\u001b[38;5;241m.\u001b[39mSequence[GRunArg]]\n\u001b[0;32m    168\u001b[0m ExtractMetaCallback \u001b[38;5;241m=\u001b[39m typing\u001b[38;5;241m.\u001b[39mCallable[[typing\u001b[38;5;241m.\u001b[39mSequence[GTypeInfo]], typing\u001b[38;5;241m.\u001b[39mSequence[GMetaArg]]\n\u001b[1;32m--> 169\u001b[0m LayerId \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDictValue\u001b[49m\n\u001b[0;32m    170\u001b[0m IndexParams \u001b[38;5;241m=\u001b[39m typing\u001b[38;5;241m.\u001b[39mDict[\u001b[38;5;28mstr\u001b[39m, typing\u001b[38;5;241m.\u001b[39mUnion[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]\n\u001b[0;32m    171\u001b[0m SearchParams \u001b[38;5;241m=\u001b[39m typing\u001b[38;5;241m.\u001b[39mDict[\u001b[38;5;28mstr\u001b[39m, typing\u001b[38;5;241m.\u001b[39mUnion[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.dnn' has no attribute 'DictValue'"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import warnings\n",
    "import os\n",
    "import uuid  # Import UUID module for generating unique filenames\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set the directories for flagged images of real and fake images\n",
    "FLAGGED_FILES_REAL_DIRECTORY = \"C:/Users/samar/Pictures/raw/real_images\"\n",
    "FLAGGED_FILES_FAKE_DIRECTORY = \"C:/Users/samar/Pictures/raw/fake_images\"\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(FLAGGED_FILES_REAL_DIRECTORY, exist_ok=True)\n",
    "os.makedirs(FLAGGED_FILES_FAKE_DIRECTORY, exist_ok=True)\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "mtcnn = MTCNN(\n",
    "    select_largest=False,\n",
    "    post_process=False,\n",
    "    device=DEVICE\n",
    ").to(DEVICE).eval()\n",
    "model = InceptionResnetV1(\n",
    "    pretrained=\"vggface2\",\n",
    "    classify=True,\n",
    "    num_classes=1,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "checkpoint = torch.load(\"resnetinceptionv1_epoch_32.pth\", map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def predict(input_image: Image.Image):\n",
    "    \"\"\"Predict the label of the input_image\"\"\"\n",
    "    face = mtcnn(input_image)\n",
    "    if face is None:\n",
    "        raise Exception('No face detected')\n",
    "    face = face.unsqueeze(0)  # add the batch dimension\n",
    "    face = F.interpolate(face, size=(256, 256), mode='bilinear', align_corners=False)\n",
    "\n",
    "    # convert the face into a numpy array to be able to plot it\n",
    "    prev_face = face.squeeze(0).permute(1, 2, 0).cpu().detach().int().numpy()\n",
    "    prev_face = prev_face.astype('uint8')\n",
    "\n",
    "    face = face.to(DEVICE)\n",
    "    face = face.to(torch.float32)\n",
    "    face = face / 255.0\n",
    "    face_image_to_plot = face.squeeze(0).permute(1, 2, 0).cpu().detach().int().numpy()\n",
    "\n",
    "    target_layers = [model.block8.branch1[-1]]\n",
    "    use_cuda = True if torch.cuda.is_available() else False\n",
    "    cam = GradCAM(model=model, target_layers=target_layers, use_cuda=use_cuda)\n",
    "    targets = [ClassifierOutputTarget(0)]\n",
    "\n",
    "    grayscale_cam = cam(input_tensor=face, targets=targets, eigen_smooth=True)\n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "    visualization = show_cam_on_image(face_image_to_plot, grayscale_cam, use_rgb=True)\n",
    "    face_with_mask = cv2.addWeighted(prev_face, 1, visualization, 0.5, 0)\n",
    "\n",
    "    # Save the flagged image based on the prediction\n",
    "    with torch.no_grad():\n",
    "        output = torch.sigmoid(model(face).squeeze(0))\n",
    "        prediction = \"real\" if output.item() < 0.5 else \"fake\" #####\n",
    "        if prediction == \"real\":\n",
    "            flagged_image_filename = str(uuid.uuid4()) + \".png\"\n",
    "            flagged_image_path = os.path.join(FLAGGED_FILES_REAL_DIRECTORY, flagged_image_filename)\n",
    "        else:\n",
    "            flagged_image_filename = str(uuid.uuid4()) + \".png\"\n",
    "            flagged_image_path = os.path.join(FLAGGED_FILES_FAKE_DIRECTORY, flagged_image_filename)\n",
    "\n",
    "        cv2.imwrite(flagged_image_path, face_with_mask)\n",
    "\n",
    "        real_prediction = 1 - output.item()\n",
    "        fake_prediction = output.item()\n",
    "\n",
    "        confidences = {\n",
    "            'real': real_prediction,\n",
    "            'fake': fake_prediction\n",
    "        }\n",
    "    return confidences, flagged_image_path\n",
    "\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=[gr.inputs.Image(label=\"Input Image\", type=\"pil\")],\n",
    "    outputs=[gr.outputs.Label(label=\"Class\"), gr.outputs.Image(label=\"Face with Explainability\", type=\"pil\")],\n",
    ").launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
